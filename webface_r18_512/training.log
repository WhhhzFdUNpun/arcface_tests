Training: 2021-10-18 21:23:59,700-rank_id: 0
Training: 2021-10-18 21:24:05,924-softmax weight init successfully!
Training: 2021-10-18 21:24:05,924-softmax weight mom init successfully!
Training: 2021-10-18 21:24:05,925-: loss                     arcface
Training: 2021-10-18 21:24:05,925-: network                  r18
Training: 2021-10-18 21:24:05,925-: resume                   False
Training: 2021-10-18 21:24:05,925-: output                   /output/webface_r18_512
Training: 2021-10-18 21:24:05,925-: dataset                  webface
Training: 2021-10-18 21:24:05,925-: embedding_size           512
Training: 2021-10-18 21:24:05,925-: sample_rate              1
Training: 2021-10-18 21:24:05,925-: fp16                     False
Training: 2021-10-18 21:24:05,925-: momentum                 0.9
Training: 2021-10-18 21:24:05,926-: weight_decay             0.0005
Training: 2021-10-18 21:24:05,926-: batch_size               512
Training: 2021-10-18 21:24:05,926-: lr                       0.1
Training: 2021-10-18 21:24:05,926-: rec                      /data
Training: 2021-10-18 21:24:05,926-: num_classes              10572
Training: 2021-10-18 21:24:05,926-: num_image                forget
Training: 2021-10-18 21:24:05,926-: num_epoch                1
Training: 2021-10-18 21:24:05,926-: warmup_epoch             -1
Training: 2021-10-18 21:24:05,926-: decay_epoch              [20, 28, 32]
Training: 2021-10-18 21:24:05,926-: val_targets              ['lfw', 'cfp_fp', 'agedb_30']
Training: 2021-10-18 21:24:05,926-: warmup_step              -479
Training: 2021-10-18 21:24:05,926-: total_step               479
Training: 2021-10-18 21:24:05,926-: decay_step               [9582, 13415, 15331]
Training: 2021-10-18 21:34:35,146-rank_id: 0
Training: 2021-10-18 21:34:52,042-softmax weight init successfully!
Training: 2021-10-18 21:34:52,043-softmax weight mom init successfully!
Training: 2021-10-18 21:34:52,043-: loss                     arcface
Training: 2021-10-18 21:34:52,043-: network                  r18
Training: 2021-10-18 21:34:52,044-: resume                   False
Training: 2021-10-18 21:34:52,044-: output                   /output/webface_r18_512
Training: 2021-10-18 21:34:52,044-: dataset                  webface
Training: 2021-10-18 21:34:52,044-: embedding_size           512
Training: 2021-10-18 21:34:52,044-: sample_rate              1
Training: 2021-10-18 21:34:52,044-: fp16                     False
Training: 2021-10-18 21:34:52,044-: momentum                 0.9
Training: 2021-10-18 21:34:52,044-: weight_decay             0.0005
Training: 2021-10-18 21:34:52,044-: batch_size               256
Training: 2021-10-18 21:34:52,044-: lr                       0.1
Training: 2021-10-18 21:34:52,044-: rec                      /data
Training: 2021-10-18 21:34:52,044-: num_classes              10572
Training: 2021-10-18 21:34:52,044-: num_image                forget
Training: 2021-10-18 21:34:52,044-: num_epoch                1
Training: 2021-10-18 21:34:52,044-: warmup_epoch             -1
Training: 2021-10-18 21:34:52,044-: decay_epoch              [20, 28, 32]
Training: 2021-10-18 21:34:52,045-: val_targets              ['lfw', 'cfp_fp', 'agedb_30']
Training: 2021-10-18 21:34:52,045-: warmup_step              -958
Training: 2021-10-18 21:34:52,045-: total_step               958
Training: 2021-10-18 21:34:52,045-: decay_step               [19164, 26830, 30663]
Training: 2021-10-18 21:41:28,865-rank_id: 0
Training: 2021-10-18 21:41:34,870-softmax weight init successfully!
Training: 2021-10-18 21:41:34,870-softmax weight mom init successfully!
Training: 2021-10-18 21:41:34,871-: loss                     arcface
Training: 2021-10-18 21:41:34,871-: network                  r18
Training: 2021-10-18 21:41:34,871-: resume                   False
Training: 2021-10-18 21:41:34,871-: output                   /output/webface_r18_512
Training: 2021-10-18 21:41:34,871-: dataset                  webface
Training: 2021-10-18 21:41:34,872-: embedding_size           512
Training: 2021-10-18 21:41:34,872-: sample_rate              1
Training: 2021-10-18 21:41:34,872-: fp16                     False
Training: 2021-10-18 21:41:34,872-: momentum                 0.9
Training: 2021-10-18 21:41:34,872-: weight_decay             0.0005
Training: 2021-10-18 21:41:34,872-: batch_size               128
Training: 2021-10-18 21:41:34,872-: lr                       0.1
Training: 2021-10-18 21:41:34,872-: rec                      /data
Training: 2021-10-18 21:41:34,872-: num_classes              10572
Training: 2021-10-18 21:41:34,872-: num_image                forget
Training: 2021-10-18 21:41:34,872-: num_epoch                1
Training: 2021-10-18 21:41:34,872-: warmup_epoch             -1
Training: 2021-10-18 21:41:34,872-: decay_epoch              [20, 28, 32]
Training: 2021-10-18 21:41:34,872-: val_targets              ['lfw', 'cfp_fp', 'agedb_30']
Training: 2021-10-18 21:41:34,872-: warmup_step              -1916
Training: 2021-10-18 21:41:34,872-: total_step               1916
Training: 2021-10-18 21:41:34,873-: decay_step               [38329, 53661, 61327]
Training: 2021-10-18 21:42:56,054-Reducer buckets have been rebuilt in this iteration.
Training: 2021-10-18 21:43:54,485-Speed 425.13 samples/sec   Loss 46.3948   LearningRate 0.0500   Epoch: 0   Global Step: 100   Required: 0 hours
Training: 2021-10-18 21:44:25,085-Speed 418.30 samples/sec   Loss 44.1255   LearningRate 0.0500   Epoch: 0   Global Step: 150   Required: 0 hours
Training: 2021-10-18 21:44:55,075-Speed 426.84 samples/sec   Loss 42.7828   LearningRate 0.0500   Epoch: 0   Global Step: 200   Required: 0 hours
Training: 2021-10-18 21:45:25,457-Speed 421.34 samples/sec   Loss 41.7497   LearningRate 0.0500   Epoch: 0   Global Step: 250   Required: 0 hours
Training: 2021-10-18 21:45:55,909-Speed 420.39 samples/sec   Loss 40.9386   LearningRate 0.0500   Epoch: 0   Global Step: 300   Required: 0 hours
Training: 2021-10-18 21:46:26,348-Speed 420.53 samples/sec   Loss 40.0482   LearningRate 0.0500   Epoch: 0   Global Step: 350   Required: 0 hours
Training: 2021-10-18 21:46:56,801-Speed 420.32 samples/sec   Loss 39.4071   LearningRate 0.0500   Epoch: 0   Global Step: 400   Required: 0 hours
Training: 2021-10-18 21:47:27,318-Speed 419.50 samples/sec   Loss 38.8057   LearningRate 0.0500   Epoch: 0   Global Step: 450   Required: 0 hours
Training: 2021-10-18 21:47:58,022-Speed 416.92 samples/sec   Loss 38.3008   LearningRate 0.0500   Epoch: 0   Global Step: 500   Required: 0 hours
Training: 2021-10-18 21:48:28,803-Speed 415.86 samples/sec   Loss 37.4331   LearningRate 0.0500   Epoch: 0   Global Step: 550   Required: 0 hours
Training: 2021-10-18 21:48:59,560-Speed 416.17 samples/sec   Loss 36.9614   LearningRate 0.0500   Epoch: 0   Global Step: 600   Required: 0 hours
Training: 2021-10-18 21:49:30,312-Speed 416.33 samples/sec   Loss 36.3953   LearningRate 0.0500   Epoch: 0   Global Step: 650   Required: 0 hours
Training: 2021-10-18 21:50:01,033-Speed 416.69 samples/sec   Loss 35.7550   LearningRate 0.0500   Epoch: 0   Global Step: 700   Required: 0 hours
Training: 2021-10-18 21:50:31,764-Speed 416.60 samples/sec   Loss 35.2486   LearningRate 0.0500   Epoch: 0   Global Step: 750   Required: 0 hours
Training: 2021-10-18 21:51:02,637-Speed 414.61 samples/sec   Loss 34.7004   LearningRate 0.0500   Epoch: 0   Global Step: 800   Required: 0 hours
Training: 2021-10-18 21:51:33,386-Speed 416.32 samples/sec   Loss 34.2275   LearningRate 0.0500   Epoch: 0   Global Step: 850   Required: 0 hours
Training: 2021-10-18 21:52:04,068-Speed 417.24 samples/sec   Loss 33.6695   LearningRate 0.0500   Epoch: 0   Global Step: 900   Required: 0 hours
Training: 2021-10-18 21:52:34,763-Speed 417.05 samples/sec   Loss 32.9068   LearningRate 0.0500   Epoch: 0   Global Step: 950   Required: 0 hours
Training: 2021-10-18 21:53:05,340-Speed 418.63 samples/sec   Loss 32.4920   LearningRate 0.0500   Epoch: 0   Global Step: 1000   Required: 0 hours
Training: 2021-10-18 21:53:36,071-Speed 416.53 samples/sec   Loss 31.5331   LearningRate 0.0500   Epoch: 0   Global Step: 1050   Required: 0 hours
Training: 2021-10-18 21:54:06,890-Speed 415.37 samples/sec   Loss 31.3878   LearningRate 0.0500   Epoch: 0   Global Step: 1100   Required: 0 hours
Training: 2021-10-18 21:54:37,775-Speed 414.45 samples/sec   Loss 30.9351   LearningRate 0.0500   Epoch: 0   Global Step: 1150   Required: 0 hours
Training: 2021-10-18 21:55:08,643-Speed 414.72 samples/sec   Loss 30.3815   LearningRate 0.0500   Epoch: 0   Global Step: 1200   Required: 0 hours
Training: 2021-10-18 21:55:39,420-Speed 415.94 samples/sec   Loss 29.9536   LearningRate 0.0500   Epoch: 0   Global Step: 1250   Required: 0 hours
Training: 2021-10-18 21:56:10,063-Speed 417.76 samples/sec   Loss 29.6052   LearningRate 0.0500   Epoch: 0   Global Step: 1300   Required: 0 hours
Training: 2021-10-18 21:56:40,769-Speed 416.91 samples/sec   Loss 28.9118   LearningRate 0.0500   Epoch: 0   Global Step: 1350   Required: 0 hours
Training: 2021-10-18 21:57:11,392-Speed 418.03 samples/sec   Loss 28.5262   LearningRate 0.0500   Epoch: 0   Global Step: 1400   Required: 0 hours
Training: 2021-10-18 21:57:42,020-Speed 417.96 samples/sec   Loss 28.0966   LearningRate 0.0500   Epoch: 0   Global Step: 1450   Required: 0 hours
Training: 2021-10-18 21:58:12,786-Speed 416.10 samples/sec   Loss 27.5051   LearningRate 0.0500   Epoch: 0   Global Step: 1500   Required: 0 hours
Training: 2021-10-18 21:58:43,598-Speed 415.47 samples/sec   Loss 27.1955   LearningRate 0.0500   Epoch: 0   Global Step: 1550   Required: 0 hours
Training: 2021-10-18 21:59:14,454-Speed 414.88 samples/sec   Loss 26.8988   LearningRate 0.0500   Epoch: 0   Global Step: 1600   Required: 0 hours
Training: 2021-10-18 21:59:45,334-Speed 414.51 samples/sec   Loss 26.5066   LearningRate 0.0500   Epoch: 0   Global Step: 1650   Required: 0 hours
Training: 2021-10-18 22:00:16,186-Speed 414.93 samples/sec   Loss 26.1839   LearningRate 0.0500   Epoch: 0   Global Step: 1700   Required: 0 hours
Training: 2021-10-18 22:00:47,006-Speed 415.33 samples/sec   Loss 25.8055   LearningRate 0.0500   Epoch: 0   Global Step: 1750   Required: 0 hours
Training: 2021-10-18 22:01:17,740-Speed 416.52 samples/sec   Loss 25.4885   LearningRate 0.0500   Epoch: 0   Global Step: 1800   Required: 0 hours
Training: 2021-10-18 22:01:48,403-Speed 417.45 samples/sec   Loss 25.0240   LearningRate 0.0500   Epoch: 0   Global Step: 1850   Required: 0 hours
Training: 2021-10-18 22:02:19,079-Speed 417.32 samples/sec   Loss 24.9198   LearningRate 0.0500   Epoch: 0   Global Step: 1900   Required: 0 hours
Training: 2021-10-18 22:02:29,207-Pytorch Model Saved in '/output/webface_r18_512/backbone.pth'
Training: 2021-10-19 07:51:43,839-rank_id: 0
Training: 2021-10-19 07:51:49,632-softmax weight init successfully!
Training: 2021-10-19 07:51:49,632-softmax weight mom init successfully!
Training: 2021-10-19 07:51:49,633-: loss                     arcface
Training: 2021-10-19 07:51:49,633-: network                  r18
Training: 2021-10-19 07:51:49,633-: resume                   False
Training: 2021-10-19 07:51:49,633-: output                   /output/webface_r18_512
Training: 2021-10-19 07:51:49,633-: dataset                  webface
Training: 2021-10-19 07:51:49,633-: embedding_size           512
Training: 2021-10-19 07:51:49,633-: sample_rate              1
Training: 2021-10-19 07:51:49,633-: fp16                     False
Training: 2021-10-19 07:51:49,633-: momentum                 0.9
Training: 2021-10-19 07:51:49,633-: weight_decay             0.0005
Training: 2021-10-19 07:51:49,633-: batch_size               128
Training: 2021-10-19 07:51:49,634-: lr                       0.1
Training: 2021-10-19 07:51:49,634-: rec                      /data
Training: 2021-10-19 07:51:49,634-: num_classes              10572
Training: 2021-10-19 07:51:49,634-: num_image                forget
Training: 2021-10-19 07:51:49,634-: num_epoch                1
Training: 2021-10-19 07:51:49,634-: warmup_epoch             -1
Training: 2021-10-19 07:51:49,634-: decay_epoch              [20, 30, 40]
Training: 2021-10-19 07:51:49,634-: val_targets              ['lfw', 'cfp_fp', 'agedb_30']
Training: 2021-10-19 07:51:49,634-: warmup_step              -1241
Training: 2021-10-19 07:51:49,634-: total_step               1241
Training: 2021-10-19 07:51:49,634-: decay_step               [24837, 37256, 49674]
Training: 2021-10-19 07:53:09,711-Reducer buckets have been rebuilt in this iteration.
Training: 2021-10-19 07:54:01,043-Speed 485.05 samples/sec   Loss 45.4002   LearningRate 0.0500   Epoch: 0   Global Step: 100   Required: 0 hours
Training: 2021-10-19 07:54:28,257-Speed 470.41 samples/sec   Loss 43.9625   LearningRate 0.0500   Epoch: 0   Global Step: 150   Required: 0 hours
Training: 2021-10-19 07:54:54,833-Speed 481.71 samples/sec   Loss 42.8136   LearningRate 0.0500   Epoch: 0   Global Step: 200   Required: 0 hours
Training: 2021-10-19 07:55:21,358-Speed 482.64 samples/sec   Loss 41.9080   LearningRate 0.0500   Epoch: 0   Global Step: 250   Required: 0 hours
Training: 2021-10-19 07:55:48,346-Speed 474.35 samples/sec   Loss 41.1643   LearningRate 0.0500   Epoch: 0   Global Step: 300   Required: 0 hours
Training: 2021-10-19 07:56:15,451-Speed 472.27 samples/sec   Loss 40.5354   LearningRate 0.0500   Epoch: 0   Global Step: 350   Required: 0 hours
Training: 2021-10-19 07:56:42,495-Speed 473.37 samples/sec   Loss 39.9910   LearningRate 0.0500   Epoch: 0   Global Step: 400   Required: 0 hours
Training: 2021-10-19 07:57:09,576-Speed 472.70 samples/sec   Loss 39.4234   LearningRate 0.0500   Epoch: 0   Global Step: 450   Required: 0 hours
Training: 2021-10-19 07:57:36,797-Speed 470.30 samples/sec   Loss 38.9636   LearningRate 0.0500   Epoch: 0   Global Step: 500   Required: 0 hours
Training: 2021-10-19 07:58:04,154-Speed 467.95 samples/sec   Loss 38.4267   LearningRate 0.0500   Epoch: 0   Global Step: 550   Required: 0 hours
Training: 2021-10-19 07:58:31,539-Speed 467.47 samples/sec   Loss 38.0595   LearningRate 0.0500   Epoch: 0   Global Step: 600   Required: 0 hours
Training: 2021-10-19 07:58:58,894-Speed 467.95 samples/sec   Loss 37.5190   LearningRate 0.0500   Epoch: 0   Global Step: 650   Required: 0 hours
Training: 2021-10-19 07:59:26,294-Speed 467.22 samples/sec   Loss 36.9819   LearningRate 0.0500   Epoch: 0   Global Step: 700   Required: 0 hours
Training: 2021-10-19 07:59:53,629-Speed 468.28 samples/sec   Loss 36.6525   LearningRate 0.0500   Epoch: 0   Global Step: 750   Required: 0 hours
Training: 2021-10-19 08:00:20,935-Speed 468.81 samples/sec   Loss 36.1503   LearningRate 0.0500   Epoch: 0   Global Step: 800   Required: 0 hours
Training: 2021-10-19 08:00:48,228-Speed 469.05 samples/sec   Loss 35.5235   LearningRate 0.0500   Epoch: 0   Global Step: 850   Required: 0 hours
Training: 2021-10-19 08:01:15,543-Speed 468.66 samples/sec   Loss 35.0077   LearningRate 0.0500   Epoch: 0   Global Step: 900   Required: 0 hours
Training: 2021-10-19 08:01:42,923-Speed 467.56 samples/sec   Loss 34.5004   LearningRate 0.0500   Epoch: 0   Global Step: 950   Required: 0 hours
Training: 2021-10-19 08:02:10,337-Speed 466.97 samples/sec   Loss 33.9445   LearningRate 0.0500   Epoch: 0   Global Step: 1000   Required: 0 hours
Training: 2021-10-19 08:02:37,793-Speed 466.26 samples/sec   Loss 33.5106   LearningRate 0.0500   Epoch: 0   Global Step: 1050   Required: 0 hours
Training: 2021-10-19 08:03:05,210-Speed 466.92 samples/sec   Loss 32.8854   LearningRate 0.0500   Epoch: 0   Global Step: 1100   Required: 0 hours
Training: 2021-10-19 08:03:32,640-Speed 466.70 samples/sec   Loss 32.4533   LearningRate 0.0500   Epoch: 0   Global Step: 1150   Required: 0 hours
Training: 2021-10-19 08:04:00,043-Speed 467.17 samples/sec   Loss 31.8163   LearningRate 0.0500   Epoch: 0   Global Step: 1200   Required: 0 hours
Training: 2021-10-19 08:04:23,231-Pytorch Model Saved in '/output/webface_r18_512/backbone.pth'
