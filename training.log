Training: 2021-10-18 13:27:36,470-rank_id: 0
Training: 2021-10-18 13:27:43,017-softmax weight init successfully!
Training: 2021-10-18 13:27:43,017-softmax weight mom init successfully!
Training: 2021-10-18 13:27:43,018-: loss                     arcface
Training: 2021-10-18 13:27:43,018-: network                  r18
Training: 2021-10-18 13:27:43,018-: resume                   False
Training: 2021-10-18 13:27:43,018-: output                   /output
Training: 2021-10-18 13:27:43,018-: dataset                  webface
Training: 2021-10-18 13:27:43,018-: embedding_size           512
Training: 2021-10-18 13:27:43,018-: sample_rate              1
Training: 2021-10-18 13:27:43,018-: fp16                     False
Training: 2021-10-18 13:27:43,019-: momentum                 0.9
Training: 2021-10-18 13:27:43,019-: weight_decay             0.0005
Training: 2021-10-18 13:27:43,019-: batch_size               64
Training: 2021-10-18 13:27:43,019-: lr                       0.1
Training: 2021-10-18 13:27:43,019-: rec                      /data
Training: 2021-10-18 13:27:43,019-: num_classes              10572
Training: 2021-10-18 13:27:43,019-: num_image                forget
Training: 2021-10-18 13:27:43,019-: num_epoch                1
Training: 2021-10-18 13:27:43,019-: warmup_epoch             -1
Training: 2021-10-18 13:27:43,019-: decay_epoch              [20, 28, 32]
Training: 2021-10-18 13:27:43,019-: val_targets              ['lfw', 'cfp_fp', 'agedb_30']
Training: 2021-10-18 13:27:43,019-: warmup_step              -1916
Training: 2021-10-18 13:27:43,019-: total_step               1916
Training: 2021-10-18 13:27:43,019-: decay_step               [38329, 53661, 61327]
Training: 2021-10-18 13:40:36,882-rank_id: 0
Training: 2021-10-18 13:40:42,920-softmax weight init successfully!
Training: 2021-10-18 13:40:42,920-softmax weight mom init successfully!
Training: 2021-10-18 13:40:42,921-: loss                     arcface
Training: 2021-10-18 13:40:42,921-: network                  r18
Training: 2021-10-18 13:40:42,921-: resume                   False
Training: 2021-10-18 13:40:42,921-: output                   /output
Training: 2021-10-18 13:40:42,921-: dataset                  webface
Training: 2021-10-18 13:40:42,921-: embedding_size           512
Training: 2021-10-18 13:40:42,921-: sample_rate              1
Training: 2021-10-18 13:40:42,921-: fp16                     False
Training: 2021-10-18 13:40:42,921-: momentum                 0.9
Training: 2021-10-18 13:40:42,921-: weight_decay             0.0005
Training: 2021-10-18 13:40:42,921-: batch_size               64
Training: 2021-10-18 13:40:42,921-: lr                       0.1
Training: 2021-10-18 13:40:42,922-: rec                      /data
Training: 2021-10-18 13:40:42,922-: num_classes              10572
Training: 2021-10-18 13:40:42,922-: num_image                forget
Training: 2021-10-18 13:40:42,922-: num_epoch                1
Training: 2021-10-18 13:40:42,922-: warmup_epoch             -1
Training: 2021-10-18 13:40:42,922-: decay_epoch              [20, 28, 32]
Training: 2021-10-18 13:40:42,922-: val_targets              ['lfw', 'cfp_fp', 'agedb_30']
Training: 2021-10-18 13:40:42,922-: warmup_step              -3832
Training: 2021-10-18 13:40:42,922-: total_step               3832
Training: 2021-10-18 13:40:42,922-: decay_step               [76659, 107323, 122655]
Training: 2021-10-18 13:42:02,598-Reducer buckets have been rebuilt in this iteration.
Training: 2021-10-18 13:42:32,733-Speed 418.58 samples/sec   Loss 47.1615   LearningRate 0.0250   Epoch: 0   Global Step: 100   Required: 0 hours
Training: 2021-10-18 13:42:48,341-Speed 410.13 samples/sec   Loss 46.0536   LearningRate 0.0250   Epoch: 0   Global Step: 150   Required: 0 hours
Training: 2021-10-18 13:43:04,256-Speed 402.25 samples/sec   Loss 44.9172   LearningRate 0.0250   Epoch: 0   Global Step: 200   Required: 0 hours
Training: 2021-10-18 13:43:20,144-Speed 402.89 samples/sec   Loss 44.1638   LearningRate 0.0250   Epoch: 0   Global Step: 250   Required: 0 hours
Training: 2021-10-18 13:45:14,465-rank_id: 0
Training: 2021-10-18 13:45:20,737-softmax weight init successfully!
Training: 2021-10-18 13:45:20,737-softmax weight mom init successfully!
Training: 2021-10-18 13:45:20,738-: loss                     arcface
Training: 2021-10-18 13:45:20,738-: network                  r18
Training: 2021-10-18 13:45:20,738-: resume                   False
Training: 2021-10-18 13:45:20,738-: output                   /output
Training: 2021-10-18 13:45:20,738-: dataset                  webface
Training: 2021-10-18 13:45:20,738-: embedding_size           512
Training: 2021-10-18 13:45:20,738-: sample_rate              1
Training: 2021-10-18 13:45:20,738-: fp16                     False
Training: 2021-10-18 13:45:20,738-: momentum                 0.9
Training: 2021-10-18 13:45:20,738-: weight_decay             0.0005
Training: 2021-10-18 13:45:20,738-: batch_size               64
Training: 2021-10-18 13:45:20,738-: lr                       0.1
Training: 2021-10-18 13:45:20,738-: rec                      /data
Training: 2021-10-18 13:45:20,739-: num_classes              10572
Training: 2021-10-18 13:45:20,739-: num_image                forget
Training: 2021-10-18 13:45:20,739-: num_epoch                1
Training: 2021-10-18 13:45:20,739-: warmup_epoch             -1
Training: 2021-10-18 13:45:20,739-: decay_epoch              [20, 28, 32]
Training: 2021-10-18 13:45:20,739-: val_targets              ['lfw', 'cfp_fp', 'agedb_30']
Training: 2021-10-18 13:45:20,739-: warmup_step              -2555
Training: 2021-10-18 13:45:20,739-: total_step               2555
Training: 2021-10-18 13:45:20,739-: decay_step               [51106, 71549, 81770]
Training: 2021-10-18 13:57:17,093-rank_id: 0
Training: 2021-10-18 14:13:23,874-rank_id: 0
Training: 2021-10-18 14:28:17,631-rank_id: 0
Training: 2021-10-18 15:45:36,325-rank_id: 0
Training: 2021-10-18 15:45:42,595-softmax weight init successfully!
Training: 2021-10-18 15:45:42,595-softmax weight mom init successfully!
Training: 2021-10-18 15:45:42,595-: loss                     arcface
Training: 2021-10-18 15:45:42,596-: network                  r18
Training: 2021-10-18 15:45:42,596-: resume                   False
Training: 2021-10-18 15:45:42,596-: output                   /output
Training: 2021-10-18 15:45:42,596-: dataset                  webface
Training: 2021-10-18 15:45:42,596-: embedding_size           512
Training: 2021-10-18 15:45:42,596-: sample_rate              1
Training: 2021-10-18 15:45:42,596-: fp16                     False
Training: 2021-10-18 15:45:42,596-: momentum                 0.9
Training: 2021-10-18 15:45:42,596-: weight_decay             0.0005
Training: 2021-10-18 15:45:42,596-: batch_size               64
Training: 2021-10-18 15:45:42,596-: lr                       0.1
Training: 2021-10-18 15:45:42,596-: rec                      /data
Training: 2021-10-18 15:45:42,596-: num_classes              10572
Training: 2021-10-18 15:45:42,596-: num_image                forget
Training: 2021-10-18 15:45:42,596-: num_epoch                1
Training: 2021-10-18 15:45:42,596-: warmup_epoch             -1
Training: 2021-10-18 15:45:42,596-: decay_epoch              [20, 28, 32]
Training: 2021-10-18 15:45:42,597-: val_targets              ['lfw', 'cfp_fp', 'agedb_30']
Training: 2021-10-18 15:45:42,597-: warmup_step              -2555
Training: 2021-10-18 15:45:42,597-: total_step               2555
Training: 2021-10-18 15:45:42,597-: decay_step               [51106, 71549, 81770]
Training: 2021-10-18 16:22:16,173-rank_id: 0
Training: 2021-10-18 16:22:22,278-softmax weight init successfully!
Training: 2021-10-18 16:22:22,278-softmax weight mom init successfully!
Training: 2021-10-18 16:22:22,279-: loss                     arcface
Training: 2021-10-18 16:22:22,279-: network                  r18
Training: 2021-10-18 16:22:22,279-: resume                   False
Training: 2021-10-18 16:22:22,279-: output                   /output
Training: 2021-10-18 16:22:22,279-: dataset                  webface
Training: 2021-10-18 16:22:22,279-: embedding_size           512
Training: 2021-10-18 16:22:22,279-: sample_rate              1
Training: 2021-10-18 16:22:22,280-: fp16                     False
Training: 2021-10-18 16:22:22,280-: momentum                 0.9
Training: 2021-10-18 16:22:22,280-: weight_decay             0.0005
Training: 2021-10-18 16:22:22,280-: batch_size               64
Training: 2021-10-18 16:22:22,280-: lr                       0.1
Training: 2021-10-18 16:22:22,280-: rec                      /data
Training: 2021-10-18 16:22:22,280-: num_classes              10572
Training: 2021-10-18 16:22:22,280-: num_image                forget
Training: 2021-10-18 16:22:22,280-: num_epoch                1
Training: 2021-10-18 16:22:22,280-: warmup_epoch             -1
Training: 2021-10-18 16:22:22,280-: decay_epoch              [20, 28, 32]
Training: 2021-10-18 16:22:22,280-: val_targets              ['lfw', 'cfp_fp', 'agedb_30']
Training: 2021-10-18 16:22:22,280-: warmup_step              -3832
Training: 2021-10-18 16:22:22,280-: total_step               3832
Training: 2021-10-18 16:22:22,280-: decay_step               [76659, 107323, 122655]
Training: 2021-10-18 16:23:43,071-Reducer buckets have been rebuilt in this iteration.
Training: 2021-10-18 16:24:48,240-Speed 186.88 samples/sec   Loss 46.9270   LearningRate 0.0250   Epoch: 0   Global Step: 100   Required: 1 hours
Training: 2021-10-18 16:25:22,305-Speed 187.90 samples/sec   Loss 45.9165   LearningRate 0.0250   Epoch: 0   Global Step: 150   Required: 1 hours
Training: 2021-10-18 16:25:56,954-Speed 184.73 samples/sec   Loss 44.9413   LearningRate 0.0250   Epoch: 0   Global Step: 200   Required: 1 hours
Training: 2021-10-18 16:26:30,783-Speed 189.21 samples/sec   Loss 44.0690   LearningRate 0.0250   Epoch: 0   Global Step: 250   Required: 1 hours
Training: 2021-10-18 16:27:04,799-Speed 188.16 samples/sec   Loss 43.3738   LearningRate 0.0250   Epoch: 0   Global Step: 300   Required: 1 hours
Training: 2021-10-18 16:27:37,357-Speed 196.60 samples/sec   Loss 42.8092   LearningRate 0.0250   Epoch: 0   Global Step: 350   Required: 1 hours
Training: 2021-10-18 16:28:09,672-Speed 198.07 samples/sec   Loss 42.1941   LearningRate 0.0250   Epoch: 0   Global Step: 400   Required: 1 hours
Training: 2021-10-18 16:28:42,080-Speed 197.50 samples/sec   Loss 41.8060   LearningRate 0.0250   Epoch: 0   Global Step: 450   Required: 1 hours
Training: 2021-10-18 16:29:13,314-Speed 204.92 samples/sec   Loss 41.3779   LearningRate 0.0250   Epoch: 0   Global Step: 500   Required: 1 hours
Training: 2021-10-18 16:29:44,639-Speed 204.34 samples/sec   Loss 40.9697   LearningRate 0.0250   Epoch: 0   Global Step: 550   Required: 1 hours
Training: 2021-10-18 16:30:15,320-Speed 208.62 samples/sec   Loss 40.6308   LearningRate 0.0250   Epoch: 0   Global Step: 600   Required: 1 hours
Training: 2021-10-18 16:30:44,237-Speed 221.35 samples/sec   Loss 40.1041   LearningRate 0.0250   Epoch: 0   Global Step: 650   Required: 1 hours
Training: 2021-10-18 16:31:10,574-Speed 243.03 samples/sec   Loss 39.6434   LearningRate 0.0250   Epoch: 0   Global Step: 700   Required: 1 hours
Training: 2021-10-18 16:31:54,350-Speed 146.21 samples/sec   Loss 39.4137   LearningRate 0.0250   Epoch: 0   Global Step: 750   Required: 1 hours
Training: 2021-10-18 16:32:21,603-Speed 234.87 samples/sec   Loss 38.8824   LearningRate 0.0250   Epoch: 0   Global Step: 800   Required: 1 hours
Training: 2021-10-18 16:32:44,576-Speed 278.63 samples/sec   Loss 38.5488   LearningRate 0.0250   Epoch: 0   Global Step: 850   Required: 1 hours
Training: 2021-10-18 16:33:06,104-Speed 297.34 samples/sec   Loss 38.3510   LearningRate 0.0250   Epoch: 0   Global Step: 900   Required: 1 hours
Training: 2021-10-18 16:33:25,786-Speed 325.23 samples/sec   Loss 38.0837   LearningRate 0.0250   Epoch: 0   Global Step: 950   Required: 0 hours
Training: 2021-10-18 16:33:42,272-Speed 388.28 samples/sec   Loss 37.6822   LearningRate 0.0250   Epoch: 0   Global Step: 1000   Required: 0 hours
Training: 2021-10-18 16:33:58,912-Speed 384.70 samples/sec   Loss 37.0610   LearningRate 0.0250   Epoch: 0   Global Step: 1050   Required: 0 hours
Training: 2021-10-18 16:34:14,881-Speed 400.86 samples/sec   Loss 36.8198   LearningRate 0.0250   Epoch: 0   Global Step: 1100   Required: 0 hours
Training: 2021-10-18 16:34:30,780-Speed 402.64 samples/sec   Loss 36.5672   LearningRate 0.0250   Epoch: 0   Global Step: 1150   Required: 0 hours
Training: 2021-10-18 16:34:46,694-Speed 402.25 samples/sec   Loss 36.2708   LearningRate 0.0250   Epoch: 0   Global Step: 1200   Required: 0 hours
Training: 2021-10-18 16:35:02,594-Speed 402.61 samples/sec   Loss 35.8313   LearningRate 0.0250   Epoch: 0   Global Step: 1250   Required: 0 hours
Training: 2021-10-18 16:35:18,482-Speed 402.90 samples/sec   Loss 35.5221   LearningRate 0.0250   Epoch: 0   Global Step: 1300   Required: 0 hours
Training: 2021-10-18 16:35:34,391-Speed 402.37 samples/sec   Loss 35.2985   LearningRate 0.0250   Epoch: 0   Global Step: 1350   Required: 0 hours
Training: 2021-10-18 16:35:50,340-Speed 401.35 samples/sec   Loss 34.6233   LearningRate 0.0250   Epoch: 0   Global Step: 1400   Required: 0 hours
Training: 2021-10-18 16:36:06,293-Speed 401.26 samples/sec   Loss 34.4485   LearningRate 0.0250   Epoch: 0   Global Step: 1450   Required: 0 hours
Training: 2021-10-18 16:36:22,230-Speed 401.68 samples/sec   Loss 34.3550   LearningRate 0.0250   Epoch: 0   Global Step: 1500   Required: 0 hours
Training: 2021-10-18 16:36:38,199-Speed 400.85 samples/sec   Loss 33.8885   LearningRate 0.0250   Epoch: 0   Global Step: 1550   Required: 0 hours
Training: 2021-10-18 16:36:54,192-Speed 400.28 samples/sec   Loss 33.7128   LearningRate 0.0250   Epoch: 0   Global Step: 1600   Required: 0 hours
Training: 2021-10-18 16:37:10,167-Speed 400.70 samples/sec   Loss 33.5333   LearningRate 0.0250   Epoch: 0   Global Step: 1650   Required: 0 hours
Training: 2021-10-18 16:37:26,158-Speed 400.33 samples/sec   Loss 33.0197   LearningRate 0.0250   Epoch: 0   Global Step: 1700   Required: 0 hours
Training: 2021-10-18 16:37:42,123-Speed 400.95 samples/sec   Loss 32.8134   LearningRate 0.0250   Epoch: 0   Global Step: 1750   Required: 0 hours
Training: 2021-10-18 16:37:58,116-Speed 400.28 samples/sec   Loss 32.5825   LearningRate 0.0250   Epoch: 0   Global Step: 1800   Required: 0 hours
Training: 2021-10-18 16:38:14,063-Speed 401.43 samples/sec   Loss 31.9988   LearningRate 0.0250   Epoch: 0   Global Step: 1850   Required: 0 hours
Training: 2021-10-18 16:38:30,023-Speed 401.09 samples/sec   Loss 31.8939   LearningRate 0.0250   Epoch: 0   Global Step: 1900   Required: 0 hours
Training: 2021-10-18 16:38:45,949-Speed 401.95 samples/sec   Loss 31.6680   LearningRate 0.0250   Epoch: 0   Global Step: 1950   Required: 0 hours
Training: 2021-10-18 16:39:01,862-Speed 402.26 samples/sec   Loss 31.3692   LearningRate 0.0250   Epoch: 0   Global Step: 2000   Required: 0 hours
Training: 2021-10-18 16:39:45,480-[lfw][2000]XNorm: 23.623902
Training: 2021-10-18 16:39:45,480-[lfw][2000]Accuracy-Flip: 0.91350+-0.01168
Training: 2021-10-18 16:39:45,480-[lfw][2000]Accuracy-Highest: 0.91350
Training: 2021-10-18 16:40:35,779-[cfp_fp][2000]XNorm: 23.531564
Training: 2021-10-18 16:40:35,779-[cfp_fp][2000]Accuracy-Flip: 0.65314+-0.02106
Training: 2021-10-18 16:40:35,779-[cfp_fp][2000]Accuracy-Highest: 0.65314
Training: 2021-10-18 16:41:19,227-[agedb_30][2000]XNorm: 20.166790
Training: 2021-10-18 16:41:19,228-[agedb_30][2000]Accuracy-Flip: 0.66600+-0.01873
Training: 2021-10-18 16:41:19,228-[agedb_30][2000]Accuracy-Highest: 0.66600
Training: 2021-10-18 16:41:35,262-Speed 41.72 samples/sec   Loss 30.8792   LearningRate 0.0250   Epoch: 0   Global Step: 2050   Required: 0 hours
Training: 2021-10-18 16:41:51,491-Speed 394.44 samples/sec   Loss 30.3514   LearningRate 0.0250   Epoch: 0   Global Step: 2100   Required: 0 hours
Training: 2021-10-18 16:42:07,750-Speed 393.71 samples/sec   Loss 30.5911   LearningRate 0.0250   Epoch: 0   Global Step: 2150   Required: 0 hours
Training: 2021-10-18 16:42:23,983-Speed 394.34 samples/sec   Loss 30.1799   LearningRate 0.0250   Epoch: 0   Global Step: 2200   Required: 0 hours
Training: 2021-10-18 16:42:40,218-Speed 394.30 samples/sec   Loss 30.2642   LearningRate 0.0250   Epoch: 0   Global Step: 2250   Required: 0 hours
Training: 2021-10-18 16:42:56,441-Speed 394.60 samples/sec   Loss 29.7061   LearningRate 0.0250   Epoch: 0   Global Step: 2300   Required: 0 hours
Training: 2021-10-18 16:43:12,711-Speed 393.45 samples/sec   Loss 29.4764   LearningRate 0.0250   Epoch: 0   Global Step: 2350   Required: 0 hours
Training: 2021-10-18 16:43:28,950-Speed 394.19 samples/sec   Loss 29.5465   LearningRate 0.0250   Epoch: 0   Global Step: 2400   Required: 0 hours
Training: 2021-10-18 16:43:45,195-Speed 394.08 samples/sec   Loss 29.2537   LearningRate 0.0250   Epoch: 0   Global Step: 2450   Required: 0 hours
Training: 2021-10-18 16:44:01,438-Speed 394.10 samples/sec   Loss 28.7586   LearningRate 0.0250   Epoch: 0   Global Step: 2500   Required: 0 hours
Training: 2021-10-18 16:44:17,682-Speed 394.09 samples/sec   Loss 28.9714   LearningRate 0.0250   Epoch: 0   Global Step: 2550   Required: 0 hours
Training: 2021-10-18 16:44:33,925-Speed 394.08 samples/sec   Loss 28.5327   LearningRate 0.0250   Epoch: 0   Global Step: 2600   Required: 0 hours
Training: 2021-10-18 16:44:50,169-Speed 394.09 samples/sec   Loss 28.2748   LearningRate 0.0250   Epoch: 0   Global Step: 2650   Required: 0 hours
Training: 2021-10-18 16:45:06,408-Speed 394.19 samples/sec   Loss 27.8843   LearningRate 0.0250   Epoch: 0   Global Step: 2700   Required: 0 hours
Training: 2021-10-18 16:45:22,536-Speed 396.92 samples/sec   Loss 27.6903   LearningRate 0.0250   Epoch: 0   Global Step: 2750   Required: 0 hours
Training: 2021-10-18 16:45:38,672-Speed 396.71 samples/sec   Loss 27.7626   LearningRate 0.0250   Epoch: 0   Global Step: 2800   Required: 0 hours
Training: 2021-10-18 16:45:54,779-Speed 397.42 samples/sec   Loss 27.4011   LearningRate 0.0250   Epoch: 0   Global Step: 2850   Required: 0 hours
Training: 2021-10-18 16:46:10,837-Speed 398.63 samples/sec   Loss 27.2283   LearningRate 0.0250   Epoch: 0   Global Step: 2900   Required: 0 hours
Training: 2021-10-18 16:46:26,891-Speed 398.75 samples/sec   Loss 26.9040   LearningRate 0.0250   Epoch: 0   Global Step: 2950   Required: 0 hours
Training: 2021-10-18 16:46:42,941-Speed 398.84 samples/sec   Loss 26.6922   LearningRate 0.0250   Epoch: 0   Global Step: 3000   Required: 0 hours
Training: 2021-10-18 16:46:59,007-Speed 398.42 samples/sec   Loss 26.6334   LearningRate 0.0250   Epoch: 0   Global Step: 3050   Required: 0 hours
Training: 2021-10-18 16:47:15,039-Speed 399.30 samples/sec   Loss 26.4255   LearningRate 0.0250   Epoch: 0   Global Step: 3100   Required: 0 hours
Training: 2021-10-18 16:47:31,049-Speed 399.85 samples/sec   Loss 26.2913   LearningRate 0.0250   Epoch: 0   Global Step: 3150   Required: 0 hours
Training: 2021-10-18 16:47:47,046-Speed 400.15 samples/sec   Loss 26.0697   LearningRate 0.0250   Epoch: 0   Global Step: 3200   Required: 0 hours
Training: 2021-10-18 16:48:03,024-Speed 400.64 samples/sec   Loss 25.8388   LearningRate 0.0250   Epoch: 0   Global Step: 3250   Required: 0 hours
Training: 2021-10-18 16:48:18,991-Speed 400.92 samples/sec   Loss 25.8949   LearningRate 0.0250   Epoch: 0   Global Step: 3300   Required: 0 hours
Training: 2021-10-18 16:48:34,970-Speed 400.59 samples/sec   Loss 25.5231   LearningRate 0.0250   Epoch: 0   Global Step: 3350   Required: 0 hours
Training: 2021-10-18 16:48:50,928-Speed 401.17 samples/sec   Loss 25.5550   LearningRate 0.0250   Epoch: 0   Global Step: 3400   Required: 0 hours
Training: 2021-10-18 16:49:06,912-Speed 400.49 samples/sec   Loss 25.4584   LearningRate 0.0250   Epoch: 0   Global Step: 3450   Required: 0 hours
Training: 2021-10-18 16:49:22,897-Speed 400.46 samples/sec   Loss 25.1724   LearningRate 0.0250   Epoch: 0   Global Step: 3500   Required: 0 hours
Training: 2021-10-18 16:49:38,888-Speed 400.31 samples/sec   Loss 25.0678   LearningRate 0.0250   Epoch: 0   Global Step: 3550   Required: 0 hours
Training: 2021-10-18 16:49:54,860-Speed 400.79 samples/sec   Loss 24.7867   LearningRate 0.0250   Epoch: 0   Global Step: 3600   Required: 0 hours
Training: 2021-10-18 16:50:10,866-Speed 399.95 samples/sec   Loss 24.6708   LearningRate 0.0250   Epoch: 0   Global Step: 3650   Required: 0 hours
Training: 2021-10-18 16:50:26,866-Speed 400.09 samples/sec   Loss 24.2280   LearningRate 0.0250   Epoch: 0   Global Step: 3700   Required: 0 hours
Training: 2021-10-18 16:50:42,846-Speed 400.58 samples/sec   Loss 24.4477   LearningRate 0.0250   Epoch: 0   Global Step: 3750   Required: 0 hours
Training: 2021-10-18 16:50:58,812-Speed 400.94 samples/sec   Loss 24.4201   LearningRate 0.0250   Epoch: 0   Global Step: 3800   Required: 0 hours
Training: 2021-10-18 16:51:09,651-Pytorch Model Saved in '/output/backbone.pth'
